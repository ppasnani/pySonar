#!/usr/bin/python -tt

import pyaudio
import wave
from pylab import *
import time
import Queue
import winsound
import threading
import numpy as np
import matplotlib.animation as animation
import matplotlib.pyplot as plt
import scipy
import scipy.fftpack


ChirpFile = "Sound Files/plain_chirp.wav"
transmitChirp = wave.open(ChirpFile, 'rb')
ChirpPeriod = 1

Chunk = 1024
Format = pyaudio.paInt16
SampWidth = transmitChirp.getsampwidth()
Channels = transmitChirp.getnchannels()
Rate = transmitChirp.getframerate()

#Create a synchronized queue that can only hold one list
recordQueue = Queue.Queue(Chunk)

#Callback functions for playing back and recording audio in
#non-blocking mode. See reference 4
def playcallback(in_data, frame_count, time_info, status):
    out_data = transmitChirp.readframes(frame_count)
    return (out_data , pyaudio.paContinue)

def recordcallback(in_data, frame_count, time_info, status):
    recordQueue.put(fromstring(in_data, 'Int16'))
    return (in_data, pyaudio.paContinue)   

#Require: Requires an exisitng pyAudio object which has set
#       up the port audio system
#Ensures: Plays the ChirpFile wave file over the speakers
#       if the speakers are available

#Note: look into threading this. I think the print delay is the only thing
#causing this to play properly
def chirp(p):
    while True:
        #Returns a tuple (nchannels, sampwidth, framerate, nframes, comptype, compname)
        audioParams = transmitChirp.getparams()
        playstream = p.open(format=p.get_format_from_width(audioParams[1]),
                        channels=audioParams[0],
                        rate=audioParams[2],
                        input=False,
                        output=True,
                        stream_callback=playcallback)
        audioTime = round(float(audioParams[-3]) / audioParams[2], 6)
        #print 'AudioTime:', audioTime
        #Keep just playing the chirp and showing the data
        playstream.start_stream()
        #Temporary delay. Use some function of chirp length or
        #travel time for audio to determine this after threading function
        time.sleep(ChirpPeriod)
        playstream.stop_stream()
        playstream.close()
        transmitChirp.setpos(0)

#Using [1] as reference
def show_wave(audio):
    subplot(211)
    plot(audio)
    title('Wave form and spectrogram of recorded audio')

    subplot(212)    
    audioTime = float(len(audio)) / Rate
    #print (len(audio)), 'time', audioTime
        
    spectrogram = specgram(audio, Fs = Rate, scale_by_freq=True, sides='default')
    #xlim([0, audioTime])
    pause(1.5)
    #show()

def plotspectrum(i, line, ax, rStream):
    if rStream.is_active():
        recordData = []        
        for x in range(recordQueue.qsize()):
            recordData.extend(recordQueue.get())
            recordQueue.task_done()
            
        #newim = specgram(recordData, Fs = Rate, scale_by_freq=True, sides='default')
        #im.set_data(newim)
        #if len(recordData) > 0:            
            FFT = abs(scipy.fft(recordData))
            timestep = 1 / float(Rate)
            freqs = scipy.fftpack.fftfreq(len(recordData), timestep)
            line.set_xdata(freqs)
            line.set_ydata(20*scipy.log10(FFT))
            #ax.autoscale_view()
            ax.set_ylim(0, 200)
            ax.set_xlim(-Rate/2, Rate/2)
            #print 'DUUUDE. I am FFTING', freqs
    return line,

def showspectrum(rStream):
    #Pxx, freqs, bins, im = specgram([], Fs = Rate, scale_by_freq = True, sides = 'default')
    fig, ax = plt.subplots()
    line, = ax.plot([],[])
    aniF = animation.FuncAnimation(fig, plotspectrum, interval = 25, blit = True,
                                   fargs = (line, ax, rStream))
    ax.clear()
    show()

def plotwave(i, line, ax, rStream):

    if rStream.is_active():
        recordData = []
        for x in range(recordQueue.qsize()):
            recordData.extend(recordQueue.get())
            recordQueue.task_done()
        #n = len(recordData)
        
        #k = arange(n)
        #T = n/float(Rate)
        #frq = k/T #Two sided frequency range
        #frq = frq[range(n/2)] #one sided frequency range
        #print 'Bro C', n, 'freq', frq
        #Y = fft(recordData) / n #fft computing and normalization
        #Y = Y[range(n/2)]
        #line.set_ydata(abs(Y))
        #line.set_data(abs(Y))
        old_len = len(line.get_xdata())
        xmin, xmax = ax.get_xlim()
        ax.set_xlim(old_len, old_len + len(recordData))
        line.set_xdata(append(line.get_xdata(), range(old_len, old_len + len(recordData))))
        line.set_ydata(append(line.get_ydata(), recordData))
        
    return line, 
    

def showwave(rStream):    
    #Pxx, freqs, t, fig = specgram([])
    #fig, ax = plt.specgram([1])
    fig, ax = plt.subplots()
    line, = ax.plot([], [])
    #Y Limit based on audio bit depth of 16 for now
    #
    ax.set_ylim(-1000, 1000)
    print "Brah"
    ani = animation.FuncAnimation(fig, plotwave, interval = 20, blit = True,
                                  fargs=(line, ax, rStream))
    plt.show()


def main():
    #Instantiate pyAudio
    p = pyaudio.PyAudio()
    #Open stream to record audio data from the mike
    recordstream = p.open(format=p.get_format_from_width(SampWidth),
                          channels=Channels,
                          rate=Rate,
                          input=True,
                          output=False,
                          stream_callback=recordcallback)
    #Create a thread to chirp continuously
    #t1 = threading.Thread(target=chirp, args=(p,))
    #t1.setDaemon(True)
    #t1.start()
    #Create a "thread" to record continuousl
    recordstream.start_stream()    
    #recordData = []
    showspectrum(recordstream)

    #while recordstream.is_active():        
        #Transmit "chirp" to listen for in echoes
        #chirp(p)

        #Get the recorded data from the synchronized priority queue
        #recordData = []
        #for i in range(recordQueue.qsize()):            
            #recordData.extend(recordQueue.get())
            #recordQueue.task_done()
            
        #Display it
        #show_wave(recordData)
        
    #Wait for the threads to end and cleanup
    #t1.join()
        
    recordQueue.join()
    recordstream.stop_stream()
    recordstream.close()
    
    p.terminate()

if __name__ == '__main__':
    main()
